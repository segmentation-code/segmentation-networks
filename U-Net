import os
import skimage
from skimage import io, transform
import math
import keras
import numpy as np
import tensorflow as tf
from keras import layers
from keras.layers import Input, Add, Dense, Concatenate,Activation,Reshape,Dropout, ZeroPadding2D, BatchNormalization,SeparableConv2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dot, Conv2DTranspose,Cropping2D,UpSampling2D
from keras.models import Model, load_model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import preprocess_input
import pydot
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.utils import plot_model
from keras.initializers import glorot_uniform
import scipy.misc
from matplotlib.pyplot import imshow
from keras.layers.advanced_activations import LeakyReLU, PReLU
from keras.regularizers import l2
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img  
import cv2
from keras.applications.vgg16 import VGG16
%matplotlib inline

import keras.backend as K
K.set_learning_phase(1)

def u_net(input_shape):
    X_input = Input(shape=input_shape)
    X = Conv2D(64, 3,activation='relu')(X_input)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(64, 3, activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_1=X
    X = MaxPooling2D(pool_size=(2,2), strides=(2,2))(X)
    
    
    X = Conv2D(128, 3, activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(128, 3, activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_2=X
    X = MaxPooling2D(pool_size=(2,2), strides=(2,2))(X)
    
    
    X = Conv2D(256, 3, padding='valid',activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(256, 3, padding='valid',activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_3=X
    X = MaxPooling2D(pool_size=(2,2), strides=(2,2))(X)
  
    
    X = Conv2D(512, 3, activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(512, 3, activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Dropout(0.5)(X)
    X_4=X
    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)
    
    X = Conv2D(1024, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(1024, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Dropout(0.5)(X)
    X = Conv2DTranspose(512,2,strides=(2,2))(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_crop= Cropping2D(4)(X_4)
    X = Concatenate(axis=-1)([X,X_crop])
    
    X = Conv2D(512, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(512, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2DTranspose(256,2,strides=(2,2))(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_crop= Cropping2D(16)(X_3)
    X = Concatenate(axis=-1)([X,X_crop])
    
    X = Conv2D(256, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(256, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2DTranspose(128,2,strides=(2,2))(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_crop= Cropping2D(40)(X_2)
    X = Concatenate(axis=-1)([X,X_crop])
    
    X = Conv2D(128, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(128, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2DTranspose(64,2,strides=(2,2))(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X_crop= Cropping2D(88)(X_1)
    X = Concatenate(axis=-1)([X,X_crop])
    
    X = Conv2D(64, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(64, 3,activation='relu')(X)
    X = BatchNormalization()(X)
    X = Activation('relu')(X)
    X = Conv2D(1, 1, activation='relu')(X)
    model = Model(inputs = X_input, outputs = X)
    
    return model
    
  model = u_net(input_shape=(2220, 924, 1))
  model.summary()
  model.compile(optimizer=keras.optimizers.Adam(lr=1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss = 'mean_squared_error', metrics=['accuracy'])
  model.fit(data, label,epochs = 200, batch_size = 2, shuffle = True)
